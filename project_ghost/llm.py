import json
import os
import yaml
from openai import OpenAI
from pprint import pformat
import json, re

# ==== 文件路径设置 ====
VULN_OUTPUT_PATH = "/home/xuehuanhuan/source-sink-ghidra/project_ghost/GhOST Output/bbb-250809_233749/vuln_output.json"
CONFIG_PATH = "/home/xuehuanhuan/source-sink-ghidra/project_ghost/config.yaml"
RESULT_PATH = "/home/xuehuanhuan/source-sink-ghidra/project_ghost/GhOST Output/bbb-250809_233749/vuln_analysis_results.json"

# ==== 模板字符串 ====
END_SYSTEM_TEMPLATE = "You are a static analysis expert. " "Given the final function calling a sink (e.g., strcpy, memcpy) with exact argument sizes, " "determine if there is a vulnerability. " "Take care of the santinazation or bound check." "Begin your answer with 'Yes' or 'No', followed by a brief explanation." "The provided [CALL_CONTEXT] contains the actual parameter information at the time the function is called, and you should only consider this real execution scenario." "When evaluating arguments, focus only on the relevant field for the data type (e.g., use buf_size for pointer/array types, value_range for numeric types) and ignore unrelated fields"

SYSTEM_TEMPLATE = (
    "You are a static analysis expert performing step-by-step, per-function analysis along a call chain.\n"
    "Goal: For each given function and its call context (i.e., known argument info), summarize: "
    "(a) how taint/values propagate inside this function; (b) which calls this function makes, with argument details needed for the next step.\n"
    "Output: Return ONE single-line JSON object ONLY (no Markdown/prose beyond `note`). "
    'Use EXACTLY these keys (keep arrays minimal; use "unk" for unknowns):\n'
    "{"
    '"fn":"string",'
    '"sources":[{"source_func":"string","target_var":"string"}],'
    '"calls":[{"callee":"string","args":[{"arg_index":int,"arg_origin":"param|local","buf_size":"str|unk","value_range":"str|unk","info":"str"}]}],'
    '"sink":["string"],'
    '"note":"brief natural hint if truly useful"'
    "}\n"
    "RULES:\n"
    "- Report only facts from THIS snippet or explicit user context; do NOT restate code.\n"
    '- Always list ALL calls in "calls" (including sinks); also list sinks in "sink".\n'
    "- Keep parameter features relevant to overflow/judgment (buffer size, array length, integer range).\n"
    '- Map caller→callee by argument position: use "arg_index"; mark provenance with "arg_origin".\n'
    "- Record only NEW sources created in this function.\n"
    '- Use [] or "unk" when none/unknown; no explanations beyond "note".\n'
    "- No speculation: ignore names; reason from operations and arguments.\n"
    "CONTEXT / INHERIT:\n"
    "- If the user message includes a [CALL_CONTEXT] with `arg_hints`, initialize argument details from it before analyzing code.\n"
    '- If the previous assistant JSON shows a call to THIS function, copy each callee argument’s {buf_size,value_range,info} into the corresponding "args[arg_index]" unless contradicted by current code.\n'
)


START_TEMPLATE = "As a program analyst, I give you snippets of C code generated by decompilation, " "using '{source}' as the taint source, '{sink}' as the sink, and the parameter that may be marked as the taint label to extract the taint data flow." "Pay attention to the data alias and tainted data operations. Output in the form of data flows:\n{code}"

SSMIDDLE_TEMPLATE = "Continue to analyze function according to the above taint analysis results. Pay attention to the data alias marked as the taint label." "and tainted data operations. Important! Refer to the analysis results of the upstream function to infer possible values for the current parameters." 'if you find the sink func,analyse function calls and save into the "calls" iteM:\n{code}'
MIDDLE_TEMPLATE = "Continue to analyze function according to the above taint analysis results. " "Use upstream call context to initialize current parameter details (arg_hints → args by arg_index). " "Do NOT speculate beyond provided facts.\n" "For EVERY call in this function (including library/sink calls such as strcpy/memcpy/printf), " "record it in the 'calls' array with each argument's taint,array_size,int_range,label;" "a call may have more than one arg(strncpy have three args,etc.)" "Report only facts from THIS snippet or explicit context.\n" "\n{code}"


END_TEMPLATE = "{code}\n" "Based on the above taint analysis results, analyze whether the code has CWE-120 buffer overflow vulnerability. If there is a" "vulnerability, please explain what kind of vulnerability according to CWE."
END_TEMPLATE = "{code}\n" "Task: Decide whether this call is a CWE-120 buffer overflow.\n" "Frozen world: The given argument sizes are exact and the only possible values. " "Do NOT speculate or consider any other contexts or inputs.\n" "Decision rule: If source_size > destination_size OR source_size == destination_size → answer 'Yes'. " "If source_size < destination_size → answer 'No'. " "If any required size is unknown → answer 'Yes'.\n" "give your explain"
END_TEMPLATE = "{code}\n" "Based on the above taint analysis results, determine whether the code contains a CWE-120 buffer overflow vulnerability. " "Respond with 'Yes' or 'No' as the first word of your answer, then provide a brief explanation. "
# ==== 载入配置 ====
if not os.path.isfile(CONFIG_PATH):
    raise FileNotFoundError(f"Missing config: {CONFIG_PATH}")

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    cfg = yaml.safe_load(f)

api_key = cfg.get("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("OPENAI_API_KEY missing in config.yaml")

api_base = cfg.get("API_BASE", "https://api.openai.com/v1")
model = cfg.get("MODEL", "gpt-4o-mini")
available_models = cfg.get("AVAILABLE_MODELS", [])

if model not in available_models:
    raise ValueError(f"Selected model '{model}' not in AVAILABLE_MODELS: {available_models}")

# ==== 初始化 OpenAI 客户端 ====
client = OpenAI(api_key=api_key, base_url=api_base)


# ==== 分析函数流 ====
"""def analyze_flow(flow: dict) -> str:
    source = flow.get("source")
    sink = flow.get("sink")
    func_keys = sorted(int(k) for k in flow if k.isdigit())
    funcs = [flow[str(i)] for i in func_keys]

    messages = [
        {"role": "system", "content": "You are a security auditing assistant. Help identify potential vulnerabilities in binary code."},
        {"role": "user", "content": START_TEMPLATE.format(source=sink, code=funcs[0])},
    ]
    for code in funcs[1:]:
        messages.append({"role": "user", "content": MIDDLE_TEMPLATE.format(code=code)})
    messages.append({"role": "user", "content": END_TEMPLATE})
    print(messages)
    # 发送请求
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.5,
    )
    return response.choices[0].message.content"""


def build_call_context_for(messages, target_fn: str) -> str:
    """
    从上一轮 assistant 的 JSON 中，抽取 calls 里指向 target_fn 的 args，
    生成 [CALL_CONTEXT] 文本块；若没有可用信息，返回空串。
    """

    def parse_assistant_json(text: str):
        """尽量把上一轮assistant输出解析为JSON（容错：返回None不报错）。"""
        text = text.strip()
        # 常见情况就是严格的一行JSON
        try:
            return json.loads(text)
        except Exception:
            pass
        # 退而求其次：抓第一个以{开头、}结尾的片段
        try:
            start = text.find("{")
            end = text.rfind("}")
            if start != -1 and end != -1 and end > start:
                return json.loads(text[start : end + 1])
        except Exception:
            return None
        return None

    # 找最近一条assistant消息
    for msg in reversed(messages):
        if msg.get("role") == "assistant":
            data = parse_assistant_json(msg.get("content", ""))
            if not isinstance(data, dict):
                continue
            calls = data.get("calls") or []
            sink = data.get("sink") or []
            for call in calls:
                if str(call.get("callee")) == target_fn:
                    args = call.get("args") or []
                    # 只保留我们关心的字段，缺失用 "unk"
                    slim_args = []
                    for a in args:
                        slim_args.append(
                            {
                                "param_index": a.get("arg_index", 0),
                                "buf_size": str(a.get("buf_size", "unk")),
                                "value_range": str(a.get("value_range", "unk")),
                                "info": str(a.get("info", "unk")),
                            }
                        )
                    ctx = "[CALL_CONTEXT]\n" f"callee={target_fn}\n" "arg_hints: " + json.dumps(slim_args, separators=(",", ":")) + "\n" f"target sink:{sink}\n"
                    return ctx
            break  # 最近一条assistant里没有命中就不再更早找
    return ""  # 没有可用的上游信息


FUNC_NAME_RE = re.compile(r"\b([A-Za-z_]\w*)\s*\(")


def extract_fn_name(code: str) -> str:
    """从C反编译片段里提取函数名（取第一个匹配）。"""
    m = FUNC_NAME_RE.search(code)
    return m.group(1) if m else ""


def print_messages(messages):
    for msg in messages:
        role = msg["role"].upper()
        print(f"\n[{role}]")
        # 直接打印 content，这样 \n 会换行，\t 会缩进
        print(msg["content"])


def analyze_flow(flow: dict) -> str:
    source = flow.get("source")
    sink = flow.get("sink")
    func_keys = sorted(int(k) for k in flow if k.isdigit())
    funcs = [flow[str(i)] for i in func_keys]

    # 初始化对话
    messages = [
        {"role": "system", "content": SYSTEM_TEMPLATE},
    ]

    # 首轮：发送 START_TEMPLATE
    start_msg = START_TEMPLATE.format(source=source, sink=sink, code=funcs[0])
    # start_msg = RSTART_TEMPLATE.format(sink=sink, code=funcs[-1])
    messages.append({"role": "user", "content": start_msg})
    print("=== 首轮对话 ===")
    # print(messages)
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.2,
    )
    reply = response.choices[0].message.content
    # print({"role": "assistant", "content": reply})
    final_reply = reply  # 存一下最后一次回复
    # 只是记录
    messages.append({"role": "assistant", "content": response.choices[0].message.content})

    # 中间轮：依次发送每个 MIDDLE_TEMPLATE
    for code in funcs[1:]:
        target_fn = extract_fn_name(code)
        call_ctx = build_call_context_for(messages, target_fn)
        # for code in reversed(funcs[:-1]):
        middle_msg = MIDDLE_TEMPLATE.format(code=(call_ctx + code))
        # middle_msg = RMIDDLE_TEMPLATE.format(code=code)
        messages.append({"role": "user", "content": middle_msg})
        tmp_messages = [
            {"role": "system", "content": SYSTEM_TEMPLATE},
            {"role": "user", "content": middle_msg},
        ]
        print("\n=== 中间轮对话 ===")
        response = client.chat.completions.create(
            model=model,
            messages=tmp_messages,
            temperature=0.2,
        )
        messages.append({"role": "assistant", "content": response.choices[0].message.content})

    # 最后一轮：发送 END_TEMPLATE
    code = funcs[-1]
    call_ctx = build_call_context_for(messages, sink)
    end_msg = END_TEMPLATE.format(code=call_ctx + "\n" + code)
    messages.append({"role": "user", "content": end_msg})
    # messages.append({"role": "user", "content": end_msg})

    tmp_messages = [
        {"role": "system", "content": END_SYSTEM_TEMPLATE},
        {"role": "user", "content": end_msg},
    ]
    response = client.chat.completions.create(
        model=model,
        messages=tmp_messages,
        temperature=0.2,
    )
    final_reply = response.choices[0].message.content
    messages.append({"role": "assistant", "content": final_reply})
    print_messages(messages)
    # ✅ 返回最后的回复（不返回中间的内容）
    return final_reply


# ==== 主程序 ====
def main():
    if not os.path.isfile(VULN_OUTPUT_PATH):
        raise FileNotFoundError(f"Missing input file: {VULN_OUTPUT_PATH}")

    with open(VULN_OUTPUT_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    results = {}
    for vid, flow in data.items():
        print(f"Analyzing {vid} with model {model} (API base: {api_base})...")
        # try:
        result = analyze_flow(flow)
        # except Exception as e:
        #    result = f"Error during analysis: {e}"
        results[vid] = result
        print(f"--- {vid} Result ---\n{result}\n")

    with open(RESULT_PATH, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"Analysis complete. Output written to {RESULT_PATH}")


if __name__ == "__main__":
    main()
